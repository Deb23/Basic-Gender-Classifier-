{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn.model_selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6165a40031e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#comparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#Try cross validation since we have a small dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#enable preprocessing (for MLP) under cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'sklearn.model_selection'"
     ]
    }
   ],
   "source": [
    "# Building a basic Gender Classifier using 4 sklearn classification algorithm\n",
    "\n",
    "#1 Decision Tree\n",
    "#2 Random Forest\n",
    "#3 Multi-layer Perceptron\n",
    "#4 Support Vector Machine\n",
    "\n",
    "#comparison \n",
    "#Try cross validation since we have a small dataset\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#enable preprocessing (for MLP) under cross-validation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import tree #decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "#Data: [height, weight, shoe_size]\n",
    "X = [[181, 80, 44], [177, 70, 43], [160, 60, 38], [154, 54, 37], [166, 65, 40], [190, 90, 47], [175, 64, 39],\n",
    "     [177, 70, 40], [159, 55, 37], [171, 75, 42], [181, 85, 43]]\n",
    "\n",
    "Y = ['male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male']\n",
    "\n",
    "mytest = [190,70,43]\n",
    "\n",
    "#Decision Tree\n",
    "nfolds = 5\n",
    "myscores = {}\n",
    "\n",
    "clf_DT = tree.DecisionTreeClassifier()\n",
    "#do k=5 fold crossvalidation\n",
    "scores_DT = cross_val_score(clf_DT, X,Y, cv = nfolds)\n",
    "print(\"Decision Tree scores: \",scores_DT)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" %(scores_DT.mean(), scores_DT.std()*2))\n",
    "myscores['DT'] = scores_DT.mean()\n",
    "\n",
    "#Random Forest\n",
    "#using the same training data\n",
    "clf_RF = RandomForestClassifier(n_estimators = 10)\n",
    "#cv\n",
    "scores_RF = cross_val_score(clf_RF, X,Y, cv = nfolds)\n",
    "print(\"Random Forest scores: \",scores_RF)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" %(scores_RF.mean(), scores_RF.std()*2))\n",
    "myscores['RF'] = scores_RF.mean()\n",
    "\n",
    "#Multi-layer perceptron\n",
    "#MLP is sensitive to feature scaling on the data so lets standardize \n",
    "clf_MLP = make_pipeline(preprocessing.StandardScaler(), MLPClassifier(solver= 'lbfgs', alpha = 1e-5, hidden_layer_sizes=(5,2), random_state=1))\n",
    "scores_MLP = cross_val_score(clf_MLP, X, Y, cv = nfolds)\n",
    "print(\"Multilayer Perceptron scores: \",scores_MLP)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" %(scores_MLP.mean(), scores_MLP.std()*2))\n",
    "myscores['MLP'] = scores_MLP.mean()\n",
    "\n",
    "#Support Vector Machine\n",
    "clf_SVM = svm.SVC()\n",
    "scores_SVM = cross_val_score(clf_SVM, X,Y,cv = nfolds)\n",
    "print(\"SVM scores: \",scores_SVM)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" %(scores_SVM.mean(), scores_SVM.std()*2))\n",
    "myscores['SVM'] = scores_SVM.mean()\n",
    "\n",
    "\n",
    "print('')\n",
    "\n",
    "#Decision Tree predictions\n",
    "clf_DT = clf_DT.fit(X, Y)\n",
    "prediction_DT = clf_DT.predict([mytest])\n",
    "#CHALLENGE compare their results and print the best one!\n",
    "print(\"The decision tree classifier predicts {} to be {}.\".format(mytest, prediction_DT))\n",
    "\n",
    "#Random Forest predictions\n",
    "clf_RF = clf_RF.fit(X,Y)\n",
    "prediction_RF = clf_RF.predict([mytest])\n",
    "print(\"The random forest classifier predicts {} to be {}.\".format(mytest, prediction_RF))\n",
    "\n",
    "#MLP predictions\n",
    "#clf_MLP = clf_MLP.fit(X,Y)\n",
    "#prediction_MLP = clf_MLP.predict([mytest])\n",
    "#print(\"The multi-layer perceptron classifier predicts {} to be {}.\".format(mytest, prediction_MLP))\n",
    "y_test = ['male']\n",
    "scaler = preprocessing.StandardScaler().fit(X)#Scale X\n",
    "X_transformed = scaler.transform(X)\n",
    "clf_MLP = clf_MLP.fit(X_transformed, Y)\n",
    "X_test_transformed = scaler.transform([mytest])\n",
    "#print(clf_MLP.score(X_test_transformed, y_test))\n",
    "prediction_MLP = clf_MLP.predict(X_test_transformed)\n",
    "print(\"The multilayer perceptron classifier predicts {} to be {}.\".format(mytest, prediction_MLP))\n",
    "\n",
    "#SVM predictions\n",
    "clf_SVM = clf_SVM.fit(X,Y)\n",
    "prediction_SVM = clf_SVM.predict([mytest])\n",
    "print(\"The support vector classifier predicts {} to be {}.\".format(mytest, prediction_SVM))\n",
    "\n",
    "#print(\"SVM support vectors:\\n\", clf_SVM.support_vectors_)\n",
    "#print(\"SVM support indices:\", clf_SVM.support_)\n",
    "#print(\"number of support vectors for each class:\", clf_SVM.n_support_)\n",
    "#print(mytest, X_test_transformed)\n",
    "\n",
    "#which is most accurate?\n",
    "print('')\n",
    "\n",
    "mymax = 0\n",
    "mymodel = ''\n",
    "for k in myscores:\n",
    "\tif myscores[k]>=mymax:\n",
    "\t\tmymax = myscores[k]\n",
    "\t\tmymodel = k\n",
    "\t#print(k, myscores[k])\n",
    "\n",
    "print(\"The most accurate model is {} with an accuracy of {}\".format(mymodel, mymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
